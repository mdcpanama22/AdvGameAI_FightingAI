# -*- coding: utf-8 -*-
"""BoxingRame.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vxviaRTHL9eB6r1CEl2BX_oQuDPyxmrN
"""
#--disable-window
import os
import sys
from operator import itemgetter
from datetime import datetime

from DeepQ import DeepQ

"""np.random.uniform(0, 1) -- [0, 1)"""
import gym
import gym_fightingice
import random
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import multiprocessing
from multiprocessing import Process, freeze_support
import threading

import uuid
class interAI(object):
    def __init__(self, mode):
        self.env = gym.make("FightingiceDataFrameskip-v0",
                            java_env_path="C:/Users/mdcpa/FightingAI/FightingICEV4.40")
    #obs = self.env.beginMatch()  # Collects Round 1
        #self.replay_buffer = ReplayBuffer(BUFFER_SIZE)
        self.deep_q = DeepQ()

        # A buffer that keeps the last 3 images
        self.process_buffer = []
        # Initialize buffer with the first frame
        s1, r1, _, _ = self.env.step(0)
        s2, r2, _, _ = self.env.step(0)
        s3, r3, _, _ = self.env.step(0)
        self.process_buffer = [s1, s2, s3]

    def simulate(self, path="", save=False):
        """Simulates game"""
        done = False
        tot_award = 0
        if save:
            self.env.monitor.start(path, force=True)
        self.env.reset()
        self.env.render()
        while 1:
            state = self.convert_process_buffer()
            predict_movement = self.deep_q.predict_movement(state, 0)[0]
            self.env.render()
            observation, reward, done, _ = self.env.step(predict_movement)
            tot_award += reward
            self.process_buffer.append(observation)
            self.process_buffer = self.process_buffer[1:]
        if save:
            self.env.monitor.close()